{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Add Imports",
   "id": "1abe3309f4ae1821"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-27T05:00:15.836935Z",
     "start_time": "2025-04-27T05:00:13.277940Z"
    }
   },
   "source": [
    "from models import hog_svm_model, sift_bovw_svm_model,simple_cnn_model, transfer_learning_model\n",
    "from utilities import path_retrievers, model_evaluator\n",
    "from utilities.oversampling_minority_classes import oversample_minority_classes\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define Utilities",
   "id": "e32634091414893f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T05:00:15.842254Z",
     "start_time": "2025-04-27T05:00:15.839668Z"
    }
   },
   "cell_type": "code",
   "source": "path_retriever = path_retrievers.PathRetrievers()",
   "id": "565435dd7f445f92",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train HOG + SVM\n",
   "id": "22512763f1b4ce1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T05:00:22.435034Z",
     "start_time": "2025-04-27T05:00:15.939801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = hog_svm_model.HogSvmModel()\n",
    "X, y = model.load_data(path_retriever.path_to_dataset_train_images, path_retriever.path_to_dataset_train_labels)\n",
    "model.train(X, y)\n",
    "save_path = os.path.join(path_retriever.path_to_export_trained_models, 'hog_svm_model.joblib')\n",
    "model.save_model(save_path)"
   ],
   "id": "b24e03c53372cd47",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m hog_svm_model\u001B[38;5;241m.\u001B[39mHogSvmModel()\n\u001B[1;32m----> 2\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_retriever\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath_to_dataset_train_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_retriever\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath_to_dataset_train_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain(X, y)\n\u001B[0;32m      4\u001B[0m save_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path_retriever\u001B[38;5;241m.\u001B[39mpath_to_export_trained_models, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhog_svm_model.joblib\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mask-detection\\Code\\models\\hog_svm_model.py:33\u001B[0m, in \u001B[0;36mHogSvmModel.load_data\u001B[1;34m(self, images_path, labels_path)\u001B[0m\n\u001B[0;32m     31\u001B[0m img_id \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplitext(filename)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     32\u001B[0m label_file \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(labels_path, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimg_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexists\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel_file\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(label_file, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     35\u001B[0m         label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(f\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39mstrip())\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train Sift + BoVW",
   "id": "11fe730f648294d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T01:53:42.557716Z",
     "start_time": "2025-04-27T01:53:28.932765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = sift_bovw_svm_model.SiftBovwSvmModel()\n",
    "sift_descriptors = model.load_data(path_retriever.path_to_dataset_train_images, path_retriever.path_to_dataset_train_labels)\n",
    "model.train(sift_descriptors)\n",
    "save_path = os.path.join(path_retriever.path_to_export_trained_models, 'sift_bovw_svm_model.joblib')\n",
    "model.save_model(save_path)"
   ],
   "id": "2ee3b056bff353bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8518\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train Simple CNN",
   "id": "71b7e310abd3323b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T03:48:42.139242Z",
     "start_time": "2025-04-27T03:47:52.959402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = simple_cnn_model.SimpleCNNModel()\n",
    "X, y = model.load_data(path_retriever.path_to_dataset_train_images, path_retriever.path_to_dataset_train_labels)\n",
    "model.train(X, y)\n",
    "save_path = os.path.join(path_retriever.path_to_export_trained_models, 'simple_cnn_model.keras')\n",
    "model.save_model(save_path)"
   ],
   "id": "8bf7e2b469a70495",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 69ms/step - accuracy: 0.8036 - loss: 0.4892 - val_accuracy: 0.9353 - val_loss: 0.2126\n",
      "Epoch 2/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 66ms/step - accuracy: 0.9267 - loss: 0.2457 - val_accuracy: 0.9332 - val_loss: 0.2005\n",
      "Epoch 3/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 67ms/step - accuracy: 0.9359 - loss: 0.2150 - val_accuracy: 0.9186 - val_loss: 0.2038\n",
      "Epoch 4/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 68ms/step - accuracy: 0.9364 - loss: 0.1935 - val_accuracy: 0.9311 - val_loss: 0.1891\n",
      "Epoch 5/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 69ms/step - accuracy: 0.9461 - loss: 0.1678 - val_accuracy: 0.9374 - val_loss: 0.2002\n",
      "Epoch 6/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 68ms/step - accuracy: 0.9417 - loss: 0.1635 - val_accuracy: 0.9374 - val_loss: 0.1817\n",
      "Epoch 7/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 67ms/step - accuracy: 0.9416 - loss: 0.1632 - val_accuracy: 0.9395 - val_loss: 0.1802\n",
      "Epoch 8/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 69ms/step - accuracy: 0.9588 - loss: 0.1216 - val_accuracy: 0.9457 - val_loss: 0.1983\n",
      "Epoch 9/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 69ms/step - accuracy: 0.9420 - loss: 0.1627 - val_accuracy: 0.9457 - val_loss: 0.1705\n",
      "Epoch 10/10\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 71ms/step - accuracy: 0.9559 - loss: 0.1293 - val_accuracy: 0.9478 - val_loss: 0.1700\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train Transfer Learning Model",
   "id": "f8eae3599a175e7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = transfer_learning_model.TransferLearningModel()\n",
    "X_train, y_train = model.load_data(path_retriever.path_to_dataset_train_images, path_retriever.path_to_dataset_train_labels)\n",
    "model.train(X_train, y_train, oversample = True)\n"
   ],
   "id": "90f6daedebf94dee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train Transfer Learning Without Oversampling but Balancing the Dataset",
   "id": "a95dc52bbd218a4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T04:45:26.233171Z",
     "start_time": "2025-04-27T04:37:51.980720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = transfer_learning_model.TransferLearningModel()\n",
    "X_train, y_train = model.load_data(path_retriever.path_to_dataset_train_images, path_retriever.path_to_dataset_train_labels)\n",
    "\n",
    "\n",
    "# Oversample before training\n",
    "X_train_balanced, y_train_balanced = oversample_minority_classes(X_train, y_train)\n",
    "\n",
    "# Shuffle the dataset\n",
    "indices = np.arange(len(X_train_balanced))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X_train_balanced = X_train_balanced[indices]\n",
    "y_train_balanced = y_train_balanced[indices]\n",
    "\n",
    "# Then train\n",
    "model.train(X_train_balanced, y_train_balanced, oversample = False)\n",
    "save_path = os.path.join(path_retriever.path_to_export_trained_models, 'transfer_learning_oversampled.keras')\n",
    "model.save_model(save_path)"
   ],
   "id": "f7c459a1276aa801",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\furqa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 102ms/step - accuracy: 0.3143 - loss: 1.2755 - val_accuracy: 0.3299 - val_loss: 1.0990\n",
      "Epoch 2/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 101ms/step - accuracy: 0.3198 - loss: 1.0995 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 3/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 104ms/step - accuracy: 0.3420 - loss: 1.0986 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 4/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 107ms/step - accuracy: 0.3199 - loss: 1.0987 - val_accuracy: 0.3308 - val_loss: 1.0987\n",
      "Epoch 5/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 102ms/step - accuracy: 0.3281 - loss: 1.0986 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 6/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 101ms/step - accuracy: 0.3375 - loss: 1.0986 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 7/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 101ms/step - accuracy: 0.3301 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 8/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 100ms/step - accuracy: 0.3135 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 9/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 99ms/step - accuracy: 0.3329 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 10/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 101ms/step - accuracy: 0.3234 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 11/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 102ms/step - accuracy: 0.3191 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 12/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 100ms/step - accuracy: 0.3382 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 13/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 99ms/step - accuracy: 0.3159 - loss: 1.0987 - val_accuracy: 0.3308 - val_loss: 1.0987\n",
      "Epoch 14/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 109ms/step - accuracy: 0.3222 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 15/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 99ms/step - accuracy: 0.3271 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 16/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 101ms/step - accuracy: 0.3369 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 17/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 101ms/step - accuracy: 0.3409 - loss: 1.0986 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 18/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 99ms/step - accuracy: 0.3187 - loss: 1.0987 - val_accuracy: 0.3308 - val_loss: 1.0986\n",
      "Epoch 19/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 99ms/step - accuracy: 0.3187 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0986\n",
      "Epoch 20/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 104ms/step - accuracy: 0.3348 - loss: 1.0986 - val_accuracy: 0.3308 - val_loss: 1.0987\n",
      "Epoch 21/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 105ms/step - accuracy: 0.3278 - loss: 1.0987 - val_accuracy: 0.3308 - val_loss: 1.0987\n",
      "Epoch 22/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 98ms/step - accuracy: 0.3228 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 23/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 98ms/step - accuracy: 0.3368 - loss: 1.0987 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 24/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 99ms/step - accuracy: 0.3289 - loss: 1.0987 - val_accuracy: 0.3308 - val_loss: 1.0987\n",
      "Epoch 25/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 97ms/step - accuracy: 0.3190 - loss: 1.0988 - val_accuracy: 0.3308 - val_loss: 1.0987\n",
      "Epoch 26/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 98ms/step - accuracy: 0.3293 - loss: 1.0987 - val_accuracy: 0.3308 - val_loss: 1.0988\n",
      "Epoch 27/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 98ms/step - accuracy: 0.3337 - loss: 1.0988 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 28/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 97ms/step - accuracy: 0.3357 - loss: 1.0985 - val_accuracy: 0.3299 - val_loss: 1.0987\n",
      "Epoch 29/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 100ms/step - accuracy: 0.3037 - loss: 1.0988 - val_accuracy: 0.3299 - val_loss: 1.0986\n",
      "Epoch 30/30\n",
      "\u001B[1m146/146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 98ms/step - accuracy: 0.3419 - loss: 1.0987 - val_accuracy: 0.3308 - val_loss: 1.0987\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
